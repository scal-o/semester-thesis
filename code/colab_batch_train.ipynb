{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14aabe6",
   "metadata": {},
   "source": [
    "# Batch Training on Google Colab\n",
    "\n",
    "This notebook runs batch training using the functions from `batch_runner.py`.\n",
    "\n",
    "## Setup Steps:\n",
    "1. Mount Google Drive\n",
    "2. Copy and extract data from Drive\n",
    "3. Install local packages\n",
    "4. Run batch training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca5c55",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define paths\n",
    "DRIVE_DATA_PATH = Path('/content/drive/MyDrive/semester/data')\n",
    "LOCAL_DATA_PATH = Path('/content/data')\n",
    "LIBS_PATH = Path('/content/libs')\n",
    "\n",
    "print(f\"Drive data path: {DRIVE_DATA_PATH}\")\n",
    "print(f\"Local data path: {LOCAL_DATA_PATH}\")\n",
    "print(f\"Libraries path: {LIBS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a386f",
   "metadata": {},
   "source": [
    "## 2. Copy Data from Google Drive to Colab Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac17ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create local data directory\n",
    "LOCAL_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List of tar.gz files to copy and extract\n",
    "# Modify this list based on the datasets you need\n",
    "datasets = [\n",
    "    'anaheim_L.tar.gz',\n",
    "    'anaheim_L_lhs.tar.gz',\n",
    "    'anaheim_LM_lhs.tar.gz',\n",
    "    'chicago_LM_lhs.tar.gz',\n",
    "    'sioux_falls_L.tar.gz',\n",
    "    'sioux_falls_L_lhs.tar.gz',\n",
    "    'sioux_falls_LM_lhs.tar.gz',\n",
    "]\n",
    "\n",
    "print(\"Copying and extracting datasets...\")\n",
    "for dataset in tqdm(datasets):\n",
    "    source_file = DRIVE_DATA_PATH / dataset\n",
    "    \n",
    "    if not source_file.exists():\n",
    "        print(f\"Warning: {dataset} not found in Drive, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Copy tar.gz file to local storage\n",
    "    local_tar = LOCAL_DATA_PATH / dataset\n",
    "    print(f\"\\nCopying {dataset}...\")\n",
    "    shutil.copy2(source_file, local_tar)\n",
    "    \n",
    "    # Extract tar.gz file\n",
    "    print(f\"Extracting {dataset}...\")\n",
    "    with tarfile.open(local_tar, 'r:gz') as tar:\n",
    "        tar.extractall(path=LOCAL_DATA_PATH)\n",
    "    \n",
    "    # Remove tar.gz file to save space\n",
    "    local_tar.unlink()\n",
    "    print(f\"✓ {dataset} extracted and cleaned up\")\n",
    "\n",
    "print(\"\\n✓ All datasets copied and extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae37e536",
   "metadata": {},
   "source": [
    "## 3. Verify Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0491e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List extracted data directories\n",
    "print(\"Extracted data directories:\")\n",
    "for item in sorted(LOCAL_DATA_PATH.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"  - {item.name}\")\n",
    "        # Check subdirectories\n",
    "        subdirs = [d.name for d in item.iterdir() if d.is_dir()]\n",
    "        if subdirs:\n",
    "            print(f\"    Subdirs: {', '.join(subdirs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf7fa9",
   "metadata": {},
   "source": [
    "## 4. Copy and Install Local Packages\n",
    "\n",
    "We need to install the local packages from the `libs/` folder:\n",
    "- `static-assignment`\n",
    "- `ml-static`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708e253",
   "metadata": {},
   "source": [
    "## 5. Install Required Packages\n",
    "\n",
    "Install system dependencies and Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c10b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv package manager (fast pip alternative)\n",
    "!pip install -q uv\n",
    "\n",
    "# Install static-assignment package\n",
    "print(\"Installing static-assignment package...\")\n",
    "!uv pip install -e {LIBS_PATH / 'static-assignment'}\n",
    "\n",
    "# Install ml-static package (includes batch_runner)\n",
    "print(\"\\nInstalling ml-static package...\")\n",
    "!uv pip install -e {LIBS_PATH / 'ml-static'}\n",
    "\n",
    "print(\"\\n✓ All packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c0ed8",
   "metadata": {},
   "source": [
    "## 6. Setup Working Directory and Copy Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to working directory\n",
    "os.chdir('/content')\n",
    "\n",
    "# Copy configs from libs/ml-static to current directory\n",
    "CONFIG_SOURCE = LIBS_PATH / 'ml-static' / 'configs'\n",
    "CONFIG_DEST = Path('/content/configs')\n",
    "\n",
    "if CONFIG_SOURCE.exists():\n",
    "    shutil.copytree(CONFIG_SOURCE, CONFIG_DEST, dirs_exist_ok=True)\n",
    "    print(f\"✓ Configs copied to {CONFIG_DEST}\")\n",
    "    \n",
    "    # List config files\n",
    "    print(\"\\nAvailable config files:\")\n",
    "    for f in CONFIG_DEST.iterdir():\n",
    "        print(f\"  - {f.name}\")\n",
    "else:\n",
    "    print(f\"Warning: {CONFIG_SOURCE} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe9e2e",
   "metadata": {},
   "source": [
    "## 7. Configure MLflow (Optional)\n",
    "\n",
    "Setup MLflow tracking for experiment management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set tracking URI to local directory\n",
    "mlflow.set_tracking_uri('file:///content/mlruns')\n",
    "\n",
    "# Create mlruns directory\n",
    "Path('/content/mlruns').mkdir(exist_ok=True)\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0425e",
   "metadata": {},
   "source": [
    "## 8. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠ No GPU available, training will use CPU (slower)\")\n",
    "    print(\"Tip: Runtime > Change runtime type > Hardware accelerator > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca8965",
   "metadata": {},
   "source": [
    "## 9. Run Batch Training\n",
    "\n",
    "### Option A: Using the batch_train CLI command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch training using the experiment suite\n",
    "# Make sure to adjust the suite file path if needed\n",
    "\n",
    "!batch-train --suite /content/configs/experiment_suite.yaml --config /content/configs/conf_run.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ac2c40",
   "metadata": {},
   "source": [
    "### Option B: Using Python directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b750b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_static.batch_runner import batch_train, load_experiment_suite, run_batch_experiments, ConfigManager\n",
    "from pathlib import Path\n",
    "\n",
    "# Load experiment suite\n",
    "suite_path = Path('/content/configs/experiment_suite.yaml')\n",
    "config_path = Path('/content/configs/conf_run.yaml')\n",
    "\n",
    "print(f\"Loading experiments from {suite_path}...\")\n",
    "experiments = load_experiment_suite(suite_path)\n",
    "\n",
    "print(f\"Found {len(experiments)} experiments:\")\n",
    "for exp in experiments:\n",
    "    print(f\"  - {exp['name']}: {exp.get('description', 'No description')}\")\n",
    "\n",
    "# Initialize config manager\n",
    "config_manager = ConfigManager(config_path)\n",
    "\n",
    "# Run batch experiments\n",
    "print(\"\\nStarting batch training...\")\n",
    "results = run_batch_experiments(experiments, config_manager)\n",
    "\n",
    "# Print results summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BATCH TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "for exp_name, result in results.items():\n",
    "    status_icon = \"✓\" if result['status'] == 'SUCCESS' else \"✗\"\n",
    "    print(f\"{status_icon} {exp_name}: {result['status']}\")\n",
    "    if result.get('error'):\n",
    "        print(f\"  Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43955723",
   "metadata": {},
   "source": [
    "## 10. Save Results Back to Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy MLflow artifacts back to Drive\n",
    "DRIVE_OUTPUT = Path('/content/drive/MyDrive/semester/colab_results')\n",
    "DRIVE_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy mlruns directory\n",
    "if Path('/content/mlruns').exists():\n",
    "    print(\"Copying MLflow results to Drive...\")\n",
    "    shutil.copytree(\n",
    "        '/content/mlruns',\n",
    "        DRIVE_OUTPUT / 'mlruns',\n",
    "        dirs_exist_ok=True\n",
    "    )\n",
    "    print(\"✓ Results saved to Drive\")\n",
    "\n",
    "# Copy mlartifacts directory if it exists\n",
    "if Path('/content/mlartifacts').exists():\n",
    "    print(\"Copying MLflow artifacts to Drive...\")\n",
    "    shutil.copytree(\n",
    "        '/content/mlartifacts',\n",
    "        DRIVE_OUTPUT / 'mlartifacts',\n",
    "        dirs_exist_ok=True\n",
    "    )\n",
    "    print(\"✓ Artifacts saved to Drive\")\n",
    "\n",
    "print(f\"\\n✓ All results saved to {DRIVE_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28592d31",
   "metadata": {},
   "source": [
    "## 11. View MLflow Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Get all runs\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiments = client.search_experiments()\n",
    "\n",
    "print(\"MLflow Experiments:\")\n",
    "for exp in experiments:\n",
    "    print(f\"\\nExperiment: {exp.name} (ID: {exp.experiment_id})\")\n",
    "    \n",
    "    # Get runs for this experiment\n",
    "    runs = client.search_runs(exp.experiment_id)\n",
    "    \n",
    "    if runs:\n",
    "        print(f\"  Found {len(runs)} runs\")\n",
    "        \n",
    "        # Create summary DataFrame\n",
    "        data = []\n",
    "        for run in runs:\n",
    "            data.append({\n",
    "                'run_id': run.info.run_id[:8],\n",
    "                'status': run.info.status,\n",
    "                'start_time': pd.to_datetime(run.info.start_time, unit='ms'),\n",
    "                **{k: v for k, v in run.data.params.items()},\n",
    "                **{k: v for k, v in run.data.metrics.items()}\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        display(df)\n",
    "    else:\n",
    "        print(\"  No runs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3cede3",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Runtime**: Make sure to select GPU runtime for faster training (Runtime > Change runtime type)\n",
    "- **Session timeout**: Colab sessions can timeout after inactivity. For long training runs, consider using Colab Pro or keep the tab active\n",
    "- **Storage**: Colab has limited disk space (~100GB). Monitor disk usage and clean up extracted data if needed\n",
    "- **Data location**: Adjust the `datasets` list in Step 2 based on which datasets you need\n",
    "- **Experiment suite**: Edit `/content/configs/experiment_suite.yaml` to customize experiments\n",
    "- **Config file**: Edit `/content/configs/conf_run.yaml` for baseline configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
